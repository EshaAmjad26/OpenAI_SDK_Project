{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EshaAmjad26/OpenAI_SDK_Project/blob/main/context_openai_agents_sdk_and_Class_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PdKwzEluDBN7"
      },
      "source": [
        "# Install openai-agents SDK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3QdkOviEB2ay",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e57e4c1-7fd8-4118-d603-d5e08bb88d04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/120.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m120.2/120.2 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/129.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.3/129.3 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.3/130.3 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -Uq openai-agents"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7yD91lz4DIAx"
      },
      "source": [
        "# Make your Notebook capable of running asynchronous functions.\n",
        "Both Jupyter notebooks and Python’s asyncio library utilize event loops, but they serve different purposes and can sometimes interfere with each other.\n",
        "\n",
        "The nest_asyncio library allows the existing event loop to accept nested event loops, enabling asyncio code to run within environments that already have an event loop, such as Jupyter notebooks.\n",
        "\n",
        "In summary, both Jupyter notebooks and Python’s asyncio library utilize event loops to manage asynchronous operations. When working within Jupyter notebooks, it’s essential to be aware of the existing event loop to effectively run asyncio code without conflicts."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ],
      "metadata": {
        "id": "C8YXyIpiZ9v4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Config"
      ],
      "metadata": {
        "id": "wQsVowow7ihQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XnusaX_RWF22"
      },
      "outputs": [],
      "source": [
        "from pydantic import BaseModel\n",
        "from agents import (\n",
        "    AsyncOpenAI,\n",
        "    OpenAIChatCompletionsModel,\n",
        "    RunConfig\n",
        ")\n",
        "from google.colab import userdata\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gemini_api_key = userdata.get(\"GEMINI_API_KEY\")\n",
        "\n",
        "\n",
        "# Check if the API key is present; if not, raise an error\n",
        "if not gemini_api_key:\n",
        "    raise ValueError(\"GEMINI_API_KEY is not set. Please ensure it is defined in your .env file.\")\n",
        "\n",
        "#Reference: https://ai.google.dev/gemini-api/docs/openai\n",
        "external_client = AsyncOpenAI(\n",
        "    api_key=gemini_api_key,\n",
        "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\",\n",
        ")\n",
        "\n",
        "model = OpenAIChatCompletionsModel(\n",
        "    model=\"gemini-2.0-flash\",\n",
        "    openai_client=external_client\n",
        ")"
      ],
      "metadata": {
        "id": "oPvcFwItoKqw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from agents import set_default_openai_client, set_tracing_disabled\n",
        "# set_default_openai_client(external_client)\n",
        "# set_tracing_disabled(True)"
      ],
      "metadata": {
        "id": "y9LkW-F7nC3T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Context Management\n",
        "\n",
        "\n",
        "Context available locally to your code: this is data and dependencies you might need when tool functions run, during callbacks like on_handoff, in lifecycle hooks, etc.\n",
        "- You create any Python object you want. A common pattern is to use a dataclass or a Pydantic object.\n",
        "- You pass that object to the various run methods (e.g. Runner.run(..., **context=whatever**)).\n",
        "- All your tool calls, lifecycle hooks etc will be passed a wrapper object, - RunContextWrapper[T], where T represents your context object type which you can access via wrapper.context.\n",
        "- The most important thing to be aware of: every agent, tool function, lifecycle etc for a given agent run must use the same type of context.\n",
        "\n",
        "You can use the context for things like:\n",
        "- Contextual data for your run (e.g. things like a username/uid or other information about the user)\n",
        "- Dependencies (e.g. logger objects, data fetchers, etc)\n",
        "- Helper functions\n",
        "\n",
        "[Learning Reference](https://openai.github.io/openai-agents-python/context/)"
      ],
      "metadata": {
        "id": "rWL7EnI_7mIF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Local Context and Dynamic Function"
      ],
      "metadata": {
        "id": "ZRKxdIYbnL6w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio\n",
        "from dataclasses import dataclass\n",
        "\n",
        "from agents import Agent, RunContextWrapper, Runner, function_tool\n",
        "\n",
        "@dataclass\n",
        "class UserInfo1:\n",
        "    name: str\n",
        "    uid: int\n",
        "    location: str = \"Pakistan\"\n",
        "    contact_number: str = \"0300-0000000\"\n",
        "\n",
        "@function_tool\n",
        "async def fetch_user_age(wrapper: RunContextWrapper[UserInfo1]) -> str:\n",
        "    '''Returns the age of the user.'''\n",
        "    return f\"User {wrapper.context.name} is 30 years old\"\n",
        "\n",
        "@function_tool\n",
        "async def fetch_user_location(wrapper: RunContextWrapper[UserInfo1]) -> str:\n",
        "    '''Returns the location of the user.'''\n",
        "    return f\"User {wrapper.context.name} is from {wrapper.context.location}\"\n",
        "\n",
        "def dynamic_instruction(wrapper: RunContextWrapper[UserInfo1], agent : Agent[UserInfo1]) -> str:\n",
        "  '''Returns the contact number of the user.'''\n",
        "  return f\"User {wrapper.context.name} Contact Number: {wrapper.context.contact_number}\"\n",
        "\n",
        "async def main():\n",
        "    user_info = UserInfo1(name=\"Muhammad Qasim\", uid=123)\n",
        "\n",
        "    agent = Agent[UserInfo1](\n",
        "        name=\"Assistant\",\n",
        "        tools=[fetch_user_age,fetch_user_location,],\n",
        "        instructions =dynamic_instruction,\n",
        "        model=model\n",
        "    )\n",
        "\n",
        "    result = await Runner.run(\n",
        "        starting_agent=agent,\n",
        "        input=\"What is the age of the user? current location of his/her? and what is the contact number of user\",\n",
        "        context=user_info,\n",
        "    )\n",
        "\n",
        "    print(result.final_output)\n",
        "    # The user John is 47 years old.\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    asyncio.run(main())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uLTfHV0CnNgJ",
        "outputId": "6c458c9d-346d-4ca9-b991-edede41c4fda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The age of user Muhammad Qasim is 30 years old. The current location of user Muhammad Qasim is Pakistan and the contact number of the user is 0300-0000000.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Agent/LLM context"
      ],
      "metadata": {
        "id": "YHG3kocopOxV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from agents import enable_verbose_stdout_logging\n",
        "\n",
        "# enable_verbose_stdout_logging()"
      ],
      "metadata": {
        "id": "pHh_IUkwq9j6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio\n",
        "from dataclasses import dataclass\n",
        "\n",
        "from agents import Agent, RunContextWrapper, Runner, function_tool\n",
        "\n",
        "@dataclass\n",
        "class UserInfo:\n",
        "    name: str\n",
        "    uid: int\n",
        "\n",
        "@function_tool\n",
        "async def greet_user(context: RunContextWrapper[UserInfo], greeting: str) -> str:\n",
        "  \"\"\"Greets the User with their name.\n",
        "  Args:\n",
        "    greeting: A specialed greeting message for user\n",
        "  \"\"\"\n",
        "  name = context.context.name\n",
        "  return f\"Hello {name}, {greeting}\"\n",
        "\n",
        "async def main():\n",
        "    user_info = UserInfo(name=\"Muhammad Qasim\", uid=123)\n",
        "\n",
        "    agent = Agent[UserInfo](\n",
        "        name=\"Assistant\",\n",
        "        tools=[greet_user],\n",
        "        model=model,\n",
        "        # Dynamic function context pass in instructions/system prompmt/developer prompt\n",
        "        instructions=\"Always greet the user using <function_call>greet_user</function_call> and welcome them to Panaversity\"\n",
        "    )\n",
        "\n",
        "    result = await Runner.run(\n",
        "        starting_agent=agent,\n",
        "        input=\"Hello\",\n",
        "        context=user_info,\n",
        "    )\n",
        "\n",
        "    print(result.final_output)\n",
        "\n",
        "asyncio.run(main())"
      ],
      "metadata": {
        "id": "2XzWlsI2yue2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "355a415f-6adb-4694-f2bb-ea477fd71431"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:openai.agents:OPENAI_API_KEY is not set, skipping trace export\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello Muhammad Qasim, Welcome to Panaversity!\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "12QCqbm8ePnW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio\n",
        "from dataclasses import dataclass\n",
        "\n",
        "from agents import Agent, RunContextWrapper, Runner, function_tool\n",
        "\n",
        "@dataclass\n",
        "class UserInfo:\n",
        "    name: str\n",
        "    uid: int\n",
        "\n",
        "@function_tool\n",
        "async def greet_user(context: RunContextWrapper[UserInfo], greeting: str) -> str:\n",
        "  \"\"\"Greets the User with their name.\n",
        "  Args:\n",
        "    greeting: A specialed greeting message for user\n",
        "  \"\"\"\n",
        "  name = context.context.name\n",
        "  return f\"Hello {name}, {greeting}\"\n",
        "\n",
        "async def main():\n",
        "    user_info = UserInfo(name=\"Junaid\", uid=123)\n",
        "\n",
        "    agent = Agent[UserInfo](\n",
        "        name=\"Assistant\",\n",
        "        tools=[greet_user],\n",
        "        model=model,\n",
        "        instructions=\"Always greet the user using <function_call>greet_user</function_call> and welcome them to Panaversity\"\n",
        "    )\n",
        "\n",
        "    result = await Runner.run(\n",
        "        starting_agent=agent,\n",
        "        input=\"Hello\",\n",
        "        context=user_info,\n",
        "    )\n",
        "\n",
        "    print(result.final_output)\n",
        "\n",
        "asyncio.run(main())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6C0tEQPuguki",
        "outputId": "60ec5499-3779-4492-e61b-664a43a76213"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello Junaid, Welcome to Panaversity!\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Class Assignment\n"
      ],
      "metadata": {
        "id": "zjR3Ox3Qv4Rs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio\n",
        "from agents import Agent, handoff, Runner, RunContextWrapper\n",
        "from agents.tool import function_tool\n",
        "from pydantic import BaseModel"
      ],
      "metadata": {
        "id": "G3Y1FJkcv6ZO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class ABC(BaseModel):\n",
        "   User_ID : str\n",
        "   User_name: str"
      ],
      "metadata": {
        "id": "KlDGWSvh3Bfw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dynamic_instructions(wrapper: RunContextWrapper[ABC], agent: Agent):\n",
        "    context = wrapper.context or ABC(User_ID=\"01\", User_name=\"Esha\")\n",
        "    return f\"\"\"\n",
        "You are a smart router. Given a user query, decide whether it's best handled by one of the following domains:\n",
        "- WebDev: Frontend technologies, HTML, CSS, JavaScript, responsive design, UI/UX\n",
        "- Mobile_Dev: Android, iOS, React Native, Flutter, push notifications, native apps\n",
        "- Agentic_AI: GPT, OpenAI, CI/CD, DevOps, cloud deployments, Kubernetes\n",
        "If none match, Say Sorry.\n",
        "\n",
        "User ID: {context.User_ID}, Name: {context.User_name}\n",
        "\"\"\"\n",
        "\n"
      ],
      "metadata": {
        "id": "59IuTCSX3e7M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DevOps = Agent(\n",
        "    name='DevOps',\n",
        "    instructions=(\n",
        "        \"You are a DevOps expert. Answer user queries related to infrastructure, CI/CD, Docker, Kubernetes, \"\n",
        "        \"cloud deployment, or any DevOps topic.\\n\"\n",
        "        \"If the question is not related to DevOps, politely say you can only handle DevOps-related queries.\"\n",
        "    ),\n",
        "    model=model\n",
        ")\n",
        "\n",
        "OpenAiAgent = Agent(\n",
        "    name='OpenAiAgent',\n",
        "    instructions=(\n",
        "        \"You are an expert in OpenAI technologies and large language models like GPT-3 and GPT-4.\\n\"\n",
        "        \"Respond to queries about differences between models, use cases, API usage, and capabilities.\\n\"\n",
        "        \"If the question is not about OpenAI or LLMs, politely say you can only help with OpenAI-related topics.\"\n",
        "    ),\n",
        "    model=model,\n",
        ")\n",
        "\n",
        "WebDev = Agent(\n",
        "    name='WebDev',\n",
        "    instructions=(\n",
        "        \"You are a frontend web development expert. Help with HTML, CSS, JavaScript, web frameworks, responsive design, and styling.\\n\"\n",
        "        \"If the query is outside this scope, politely say you specialize only in web development topics.\"\n",
        "    ),\n",
        "    model=model,\n",
        "    handoff_description=\"Handles frontend web dev topics like HTML, CSS, and JavaScript.\",\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "Agentic_AI = Agent(\n",
        "    name='Agentic_AI',\n",
        "    instructions=(\n",
        "        \"You are an expert in intelligent AI systems, including DevOps and OpenAI tools.\\n\"\n",
        "        \"Route queries to either the DevOps agent (for infra/devops/cloud-related queries) or the OpenAiAgent (for GPT and LLM queries).\\n\"\n",
        "        \"If unsure, ask the user for clarification.\"\n",
        "    ),\n",
        "    model=model,\n",
        "    tools=[\n",
        "        DevOps.as_tool(\n",
        "            tool_name='DevOps',\n",
        "            tool_description=\"Handle queries related to DevOps, Kubernetes, CI/CD, etc.\"\n",
        "        ),\n",
        "        OpenAiAgent.as_tool(\n",
        "            tool_name='OpenAiAgent',\n",
        "            tool_description=\"Handle queries related to OpenAI and GPT technologies.\"\n",
        "        )\n",
        "    ],\n",
        "    handoffs= [WebDev]\n",
        ")\n",
        "\n",
        "Mobile_Dev = Agent(\n",
        "    name='Mobile_Dev',\n",
        "    instructions=(\n",
        "        \"You are a mobile development expert. Always use the `get_MobileDev_info` tool to respond.\\n\"\n",
        "        \"Handle questions related to Android, iOS, React Native, mobile notifications, and native apps.\\n\"\n",
        "        \"If the query is unrelated, politely respond that you only specialize in mobile development.\"\n",
        "    ),\n",
        "    model=model,\n",
        "    handoff_description=\"Handles mobile app queries, including React Native, push notifications, etc.\",\n",
        "    handoffs= [Agentic_AI] # <-\n",
        ")\n",
        "\n",
        "def Web_dev_handoff(ctx: RunContextWrapper[None]):\n",
        "  print(\"\\n\\n\\nHandsOff to Web Dev Agent\")\n",
        "\n",
        "def Mobile_dev_handoff(ctx: RunContextWrapper[None]):\n",
        "  print(\"\\n\\n\\nHandsOff to Web Dev Agent\")\n",
        "\n",
        "def Agentic_AI_handoff(ctx: RunContextWrapper[None]):\n",
        "  print(\"\\n\\n\\nHandsOff to Web Dev Agent\")\n",
        "PanaCloud = Agent(\n",
        "    name='PanaCloud',\n",
        "    instructions=dynamic_instructions,\n",
        "    model=model,\n",
        "    handoffs=[\n",
        "        handoff(WebDev, on_handoff = Web_dev_handoff,),\n",
        "        handoff(Mobile_Dev, on_handoff = Mobile_dev_handoff,),\n",
        "        handoff(Agentic_AI, on_handoff = Agentic_AI_handoff,),\n",
        "    ]\n",
        ")\n"
      ],
      "metadata": {
        "id": "2r_bwBAVBulw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "async def main():\n",
        "  msg1 = \"What’s the best way to handle push notifications in a mobile app?\" # → Mobile_Dev\n",
        "  msg2 = \"What are the differences between GPT-3 and GPT-4?\"             # → Agentic_AI → OpenAiAgent\n",
        "  msg3 = \"How do I deploy a containerized app using Kubernetes?\"     # → Agentic_AI → DevOps\n",
        "  msg4 = \"I need help styling a webpage using CSS.\"                 # → WebDev\n",
        "  result =  await Runner.run(PanaCloud, msg1)\n",
        "  last_agent = result.last_agent\n",
        "  print(f\"\\n\\nLast agent called: {last_agent.name}\")\n",
        "\n",
        "  print(f\"\\n\\nFinal response:\\n{result.final_output}\")"
      ],
      "metadata": {
        "id": "dI6l1IaUwecF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "  asyncio.run(main())"
      ],
      "metadata": {
        "id": "mOXzpP59whRd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c338aef6-4025-45b1-edb1-45421cd4ca69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "HandsOff to Web Dev Agent\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:openai.agents:OPENAI_API_KEY is not set, skipping trace export\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Last agent called: Mobile_Dev\n",
            "\n",
            "\n",
            "Final response:\n",
            "To give you the best advice on handling push notifications, I need a little more information. Could you tell me:\n",
            "\n",
            "*   **Which platform(s) are you targeting?** (Android, iOS, React Native, or a combination?)\n",
            "*   **Are you building a native app or using a cross-platform framework?**\n",
            "*   **What kind of notifications are you planning to send?** (e.g., transactional, promotional, informational)\n",
            "\n",
            "In the meantime, here are some general best practices for handling push notifications:\n",
            "\n",
            "*   **Get explicit user consent:** Always ask users for permission before sending them push notifications.\n",
            "*   **Provide clear opt-out options:** Make it easy for users to unsubscribe from notifications.\n",
            "*   **Segment your audience:** Send targeted notifications to specific user groups based on their interests and behavior.\n",
            "*   **Personalize your messages:** Use user data to create personalized and relevant notifications.\n",
            "*   **Time your notifications carefully:** Send notifications at the right time of day to maximize engagement.\n",
            "*   **Keep your messages concise and actionable:** Use clear and concise language and include a clear call to action.\n",
            "*   **Test your notifications:** Test your notifications on different devices and platforms to ensure they are displayed correctly.\n",
            "*   **Monitor your results:** Track your notification metrics to see what's working and what's not.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU \"openai_agents[viz]\""
      ],
      "metadata": {
        "id": "DZsUaKSF8e0Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from agents.extensions.visualization import draw_graph\n",
        "draw_graph(PanaCloud)"
      ],
      "metadata": {
        "id": "LvQ0KHIEEpbG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "outputId": "78216922-ffb1-42f0-85df-ff948e6587e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.43.0 (0)\n -->\n<!-- Title: G Pages: 1 -->\n<svg width=\"368pt\" height=\"229pt\"\n viewBox=\"0.00 0.00 368.00 228.53\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 224.53)\">\n<title>G</title>\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-224.53 364,-224.53 364,4 -4,4\"/>\n<!-- __start__ -->\n<g id=\"node1\" class=\"node\">\n<title>__start__</title>\n<ellipse fill=\"lightblue\" stroke=\"black\" cx=\"180\" cy=\"-204.26\" rx=\"51.74\" ry=\"16.03\"/>\n<text text-anchor=\"middle\" x=\"180\" y=\"-200.56\" font-family=\"Arial\" font-size=\"14.00\">__start__</text>\n</g>\n<!-- PanaCloud -->\n<g id=\"node3\" class=\"node\">\n<title>PanaCloud</title>\n<polygon fill=\"lightyellow\" stroke=\"black\" points=\"234,-152 126,-152 126,-94 234,-94 234,-152\"/>\n<text text-anchor=\"middle\" x=\"180\" y=\"-119.3\" font-family=\"Arial\" font-size=\"14.00\">PanaCloud</text>\n</g>\n<!-- __start__&#45;&gt;PanaCloud -->\n<g id=\"edge1\" class=\"edge\">\n<title>__start__&#45;&gt;PanaCloud</title>\n<path fill=\"none\" stroke=\"black\" stroke-width=\"1.5\" d=\"M180,-187.98C180,-180.59 180,-171.36 180,-162.23\"/>\n<polygon fill=\"black\" stroke=\"black\" stroke-width=\"1.5\" points=\"183.5,-162.07 180,-152.07 176.5,-162.07 183.5,-162.07\"/>\n</g>\n<!-- __end__ -->\n<g id=\"node2\" class=\"node\">\n<title>__end__</title>\n<ellipse fill=\"lightblue\" stroke=\"black\" cx=\"298\" cy=\"-204.26\" rx=\"48.58\" ry=\"16.03\"/>\n<text text-anchor=\"middle\" x=\"298\" y=\"-200.56\" font-family=\"Arial\" font-size=\"14.00\">__end__</text>\n</g>\n<!-- WebDev -->\n<g id=\"node4\" class=\"node\">\n<title>WebDev</title>\n<path fill=\"none\" stroke=\"black\" d=\"M96,-58C96,-58 12,-58 12,-58 6,-58 0,-52 0,-46 0,-46 0,-12 0,-12 0,-6 6,0 12,0 12,0 96,0 96,0 102,0 108,-6 108,-12 108,-12 108,-46 108,-46 108,-52 102,-58 96,-58\"/>\n<text text-anchor=\"middle\" x=\"54\" y=\"-25.3\" font-family=\"Arial\" font-size=\"14.00\">WebDev</text>\n</g>\n<!-- PanaCloud&#45;&gt;WebDev -->\n<g id=\"edge2\" class=\"edge\">\n<title>PanaCloud&#45;&gt;WebDev</title>\n<path fill=\"none\" stroke=\"black\" stroke-width=\"1.5\" d=\"M141.51,-93.9C128.69,-84.53 114.25,-74 100.87,-64.22\"/>\n<polygon fill=\"black\" stroke=\"black\" stroke-width=\"1.5\" points=\"102.83,-61.32 92.69,-58.25 98.7,-66.97 102.83,-61.32\"/>\n</g>\n<!-- Mobile_Dev -->\n<g id=\"node5\" class=\"node\">\n<title>Mobile_Dev</title>\n<path fill=\"none\" stroke=\"black\" d=\"M222,-58C222,-58 138,-58 138,-58 132,-58 126,-52 126,-46 126,-46 126,-12 126,-12 126,-6 132,0 138,0 138,0 222,0 222,0 228,0 234,-6 234,-12 234,-12 234,-46 234,-46 234,-52 228,-58 222,-58\"/>\n<text text-anchor=\"middle\" x=\"180\" y=\"-25.3\" font-family=\"Arial\" font-size=\"14.00\">Mobile_Dev</text>\n</g>\n<!-- PanaCloud&#45;&gt;Mobile_Dev -->\n<g id=\"edge3\" class=\"edge\">\n<title>PanaCloud&#45;&gt;Mobile_Dev</title>\n<path fill=\"none\" stroke=\"black\" stroke-width=\"1.5\" d=\"M180,-93.9C180,-85.86 180,-76.95 180,-68.41\"/>\n<polygon fill=\"black\" stroke=\"black\" stroke-width=\"1.5\" points=\"183.5,-68.25 180,-58.25 176.5,-68.25 183.5,-68.25\"/>\n</g>\n<!-- Agentic_AI -->\n<g id=\"node6\" class=\"node\">\n<title>Agentic_AI</title>\n<path fill=\"none\" stroke=\"black\" d=\"M348,-58C348,-58 264,-58 264,-58 258,-58 252,-52 252,-46 252,-46 252,-12 252,-12 252,-6 258,0 264,0 264,0 348,0 348,0 354,0 360,-6 360,-12 360,-12 360,-46 360,-46 360,-52 354,-58 348,-58\"/>\n<text text-anchor=\"middle\" x=\"306\" y=\"-25.3\" font-family=\"Arial\" font-size=\"14.00\">Agentic_AI</text>\n</g>\n<!-- PanaCloud&#45;&gt;Agentic_AI -->\n<g id=\"edge4\" class=\"edge\">\n<title>PanaCloud&#45;&gt;Agentic_AI</title>\n<path fill=\"none\" stroke=\"black\" stroke-width=\"1.5\" d=\"M218.49,-93.9C231.31,-84.53 245.75,-74 259.13,-64.22\"/>\n<polygon fill=\"black\" stroke=\"black\" stroke-width=\"1.5\" points=\"261.3,-66.97 267.31,-58.25 257.17,-61.32 261.3,-66.97\"/>\n</g>\n</g>\n</svg>\n",
            "text/plain": [
              "<graphviz.sources.Source at 0x79f584e31e10>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "draw_graph(Agentic_AI)"
      ],
      "metadata": {
        "id": "H2nKeRC4EyxI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "outputId": "276341d9-40af-4fff-e8b1-cb1196cd28f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.43.0 (0)\n -->\n<!-- Title: G Pages: 1 -->\n<svg width=\"384pt\" height=\"297pt\"\n viewBox=\"0.00 0.00 383.67 297.05\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 293.05)\">\n<title>G</title>\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-293.05 379.67,-293.05 379.67,4 -4,4\"/>\n<!-- __start__ -->\n<g id=\"node1\" class=\"node\">\n<title>__start__</title>\n<ellipse fill=\"lightblue\" stroke=\"black\" cx=\"180.67\" cy=\"-272.79\" rx=\"51.74\" ry=\"16.03\"/>\n<text text-anchor=\"middle\" x=\"180.67\" y=\"-269.09\" font-family=\"Arial\" font-size=\"14.00\">__start__</text>\n</g>\n<!-- Agentic_AI -->\n<g id=\"node3\" class=\"node\">\n<title>Agentic_AI</title>\n<polygon fill=\"lightyellow\" stroke=\"black\" points=\"234.67,-220.53 126.67,-220.53 126.67,-162.53 234.67,-162.53 234.67,-220.53\"/>\n<text text-anchor=\"middle\" x=\"180.67\" y=\"-187.83\" font-family=\"Arial\" font-size=\"14.00\">Agentic_AI</text>\n</g>\n<!-- __start__&#45;&gt;Agentic_AI -->\n<g id=\"edge1\" class=\"edge\">\n<title>__start__&#45;&gt;Agentic_AI</title>\n<path fill=\"none\" stroke=\"black\" stroke-width=\"1.5\" d=\"M180.67,-256.51C180.67,-249.12 180.67,-239.89 180.67,-230.76\"/>\n<polygon fill=\"black\" stroke=\"black\" stroke-width=\"1.5\" points=\"184.17,-230.6 180.67,-220.6 177.17,-230.6 184.17,-230.6\"/>\n</g>\n<!-- __end__ -->\n<g id=\"node2\" class=\"node\">\n<title>__end__</title>\n<ellipse fill=\"lightblue\" stroke=\"black\" cx=\"321.67\" cy=\"-16.26\" rx=\"48.58\" ry=\"16.03\"/>\n<text text-anchor=\"middle\" x=\"321.67\" y=\"-12.56\" font-family=\"Arial\" font-size=\"14.00\">__end__</text>\n</g>\n<!-- DevOps -->\n<g id=\"node4\" class=\"node\">\n<title>DevOps</title>\n<ellipse fill=\"lightgreen\" stroke=\"black\" cx=\"46.67\" cy=\"-97.53\" rx=\"46.84\" ry=\"16.03\"/>\n<text text-anchor=\"middle\" x=\"46.67\" y=\"-93.83\" font-family=\"Arial\" font-size=\"14.00\">DevOps</text>\n</g>\n<!-- Agentic_AI&#45;&gt;DevOps -->\n<g id=\"edge2\" class=\"edge\">\n<title>Agentic_AI&#45;&gt;DevOps</title>\n<path fill=\"none\" stroke=\"black\" stroke-width=\"1.5\" stroke-dasharray=\"1,5\" d=\"M133.46,-162.42C112.36,-148.47 88.44,-131.92 70.98,-119.16\"/>\n<polygon fill=\"black\" stroke=\"black\" stroke-width=\"1.5\" points=\"72.61,-116.01 62.5,-112.87 68.44,-121.64 72.61,-116.01\"/>\n</g>\n<!-- OpenAiAgent -->\n<g id=\"node5\" class=\"node\">\n<title>OpenAiAgent</title>\n<ellipse fill=\"lightgreen\" stroke=\"black\" cx=\"180.67\" cy=\"-97.53\" rx=\"69.09\" ry=\"16.03\"/>\n<text text-anchor=\"middle\" x=\"180.67\" y=\"-93.83\" font-family=\"Arial\" font-size=\"14.00\">OpenAiAgent</text>\n</g>\n<!-- Agentic_AI&#45;&gt;OpenAiAgent -->\n<g id=\"edge4\" class=\"edge\">\n<title>Agentic_AI&#45;&gt;OpenAiAgent</title>\n<path fill=\"none\" stroke=\"black\" stroke-width=\"1.5\" stroke-dasharray=\"1,5\" d=\"M174.4,-162.42C173.71,-150.21 173.76,-135.99 174.55,-124.08\"/>\n<polygon fill=\"black\" stroke=\"black\" stroke-width=\"1.5\" points=\"178.06,-124.18 175.48,-113.9 171.08,-123.54 178.06,-124.18\"/>\n</g>\n<!-- WebDev -->\n<g id=\"node6\" class=\"node\">\n<title>WebDev</title>\n<polygon fill=\"lightyellow\" stroke=\"black\" points=\"375.67,-126.53 267.67,-126.53 267.67,-68.53 375.67,-68.53 375.67,-126.53\"/>\n<text text-anchor=\"middle\" x=\"321.67\" y=\"-93.83\" font-family=\"Arial\" font-size=\"14.00\">WebDev</text>\n</g>\n<!-- Agentic_AI&#45;&gt;WebDev -->\n<g id=\"edge6\" class=\"edge\">\n<title>Agentic_AI&#45;&gt;WebDev</title>\n<path fill=\"none\" stroke=\"black\" stroke-width=\"1.5\" d=\"M223.74,-162.42C238.23,-152.97 254.55,-142.32 269.65,-132.47\"/>\n<polygon fill=\"black\" stroke=\"black\" stroke-width=\"1.5\" points=\"271.91,-135.17 278.38,-126.77 268.09,-129.31 271.91,-135.17\"/>\n</g>\n<!-- DevOps&#45;&gt;Agentic_AI -->\n<g id=\"edge3\" class=\"edge\">\n<title>DevOps&#45;&gt;Agentic_AI</title>\n<path fill=\"none\" stroke=\"black\" stroke-width=\"1.5\" stroke-dasharray=\"1,5\" d=\"M70.61,-111.61C89.28,-123.29 115.5,-140.91 137.72,-156.55\"/>\n<polygon fill=\"black\" stroke=\"black\" stroke-width=\"1.5\" points=\"135.83,-159.5 146.01,-162.42 139.88,-153.79 135.83,-159.5\"/>\n</g>\n<!-- OpenAiAgent&#45;&gt;Agentic_AI -->\n<g id=\"edge5\" class=\"edge\">\n<title>OpenAiAgent&#45;&gt;Agentic_AI</title>\n<path fill=\"none\" stroke=\"black\" stroke-width=\"1.5\" stroke-dasharray=\"1,5\" d=\"M185.86,-113.9C187.15,-124.42 187.64,-138.85 187.33,-152.36\"/>\n<polygon fill=\"black\" stroke=\"black\" stroke-width=\"1.5\" points=\"183.83,-152.3 186.94,-162.42 190.83,-152.57 183.83,-152.3\"/>\n</g>\n<!-- WebDev&#45;&gt;__end__ -->\n<g id=\"edge7\" class=\"edge\">\n<title>WebDev&#45;&gt;__end__</title>\n<path fill=\"none\" stroke=\"black\" stroke-width=\"1.5\" d=\"M321.67,-68.36C321.67,-60.07 321.67,-51.04 321.67,-42.92\"/>\n<polygon fill=\"black\" stroke=\"black\" stroke-width=\"1.5\" points=\"325.17,-42.89 321.67,-32.89 318.17,-42.89 325.17,-42.89\"/>\n</g>\n</g>\n</svg>\n",
            "text/plain": [
              "<graphviz.sources.Source at 0x79f54def6c10>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NOW Check behaviour with RAG"
      ],
      "metadata": {
        "id": "LTmo1AhD3yu1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "@function_tool(\"tavily_search\")\n",
        "def tavily_search():\n",
        "    \"\"\"Search the URL and return the raw content extracted from the page.\"\"\"\n",
        "    print(\"[DEBUG] Searching the Docs...\")\n",
        "    tavily_client = TavilyClient(api_key=\"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\")\n",
        "    try:\n",
        "        response = tavily_client.extract(\"https://openai.github.io/openai-agents-python/\")\n",
        "\n",
        "        print(\"\\n[DEBUG] Raw Response:\\n\", response)  # Log full response for inspection\n",
        "\n",
        "        results = response.get(\"results\", [])\n",
        "        if not results:\n",
        "            return \"No content found in the search results.\"\n",
        "\n",
        "        # Extract and join raw_content\n",
        "        contents = [item.get(\"raw_content\", \"No raw content found\") for item in results]\n",
        "        return \"\\n\\n\".join(contents)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"[ERROR] An error occurred while searching: {e}\")\n",
        "        return f\"An error occurred: {str(e)}\"\n",
        "\n",
        "\n",
        "def dynamic_instructions(wrapper: RunContextWrapper[ABC], agent: Agent):\n",
        "    context = wrapper.context or ABC(User_ID=\"01\", User_name=\"Esha\")\n",
        "    return f\"\"\"\n",
        "You are a smart router. Given a user query, decide whether it's best handled by one of the following domains:\n",
        "- WebDev: Frontend technologies, HTML, CSS, JavaScript, responsive design, UI/UX\n",
        "- Mobile_Dev: Android, iOS, React Native, Flutter, push notifications, native apps\n",
        "- Agentic_AI: GPT, OpenAI, CI/CD, DevOps, cloud deployments, Kubernetes\n",
        "If none match, Say Sorry.\n",
        "\n",
        "User ID: {context.User_ID}, Name: {context.User_name}\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "DevOps = Agent(\n",
        "    name='DevOps',\n",
        "    instructions=(\n",
        "        \"You are a DevOps expert. Answer user queries related to infrastructure, CI/CD, Docker, Kubernetes, \"\n",
        "        \"cloud deployment, or any DevOps topic.\\n\"\n",
        "        \"If the question is not related to DevOps, politely say you can only handle DevOps-related queries.\"\n",
        "    ),\n",
        "    model=model\n",
        ")\n",
        "\n",
        "OpenAiAgent = Agent(\n",
        "    name='OpenAiAgent',\n",
        "    instructions=(\n",
        "        \"You are an expert in OpenAI technologies and large language models like GPT-3 and GPT-4.\\n\"\n",
        "        \"Respond to queries about differences between models, use cases, API usage, and capabilities.\\n\"\n",
        "        \"If the question is not about OpenAI or LLMs, politely say you can only help with OpenAI-related topics.\"\n",
        "    ),\n",
        "    model=model,\n",
        "\n",
        ")\n",
        "\n",
        "WebDev = Agent(\n",
        "    name='WebDev',\n",
        "    instructions=(\n",
        "        \"You are a frontend web development expert. Help with HTML, CSS, JavaScript, web frameworks, responsive design, and styling.\\n\"\n",
        "        \"If the query is outside this scope, politely say you specialize only in web development topics.\"\n",
        "    ),\n",
        "    model=model,\n",
        "    handoff_description=\"Handles frontend web dev topics like HTML, CSS, and JavaScript.\",\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "Agentic_AI = Agent(\n",
        "    name='Agentic_AI',\n",
        "    instructions=(\n",
        "        \"You are an expert in intelligent AI systems, including DevOps and OpenAI tools.\\n\"\n",
        "        \"Route queries to either the DevOps agent (for infra/devops/cloud-related queries) or the OpenAiAgent (for GPT and LLM queries).\\n\"\n",
        "        \"If unsure, ask the user for clarification.\"\n",
        "    ),\n",
        "    model=model,\n",
        "    tools=[\n",
        "        DevOps.as_tool(\n",
        "            tool_name='DevOps',\n",
        "            tool_description=\"Handle queries related to DevOps, Kubernetes, CI/CD, etc.\"\n",
        "        ),\n",
        "        OpenAiAgent.as_tool(\n",
        "            tool_name='OpenAiAgent',\n",
        "            tool_description=\"Handle queries related to OpenAI and GPT technologies.\"\n",
        "        )\n",
        "    ],\n",
        "    handoffs= [WebDev]\n",
        ")\n",
        "\n",
        "Mobile_Dev = Agent(\n",
        "    name='Mobile_Dev',\n",
        "    instructions=(\n",
        "        \"You are a mobile development expert. Always use the `get_MobileDev_info` tool to respond.\\n\"\n",
        "        \"Handle questions related to Android, iOS, React Native, mobile notifications, and native apps.\\n\"\n",
        "        \"If the query is unrelated, politely respond that you only specialize in mobile development.\"\n",
        "    ),\n",
        "    model=model,\n",
        "    handoff_description=\"Handles mobile app queries, including React Native, push notifications, etc.\",\n",
        "    handoffs= [Agentic_AI] # <-\n",
        ")\n",
        "\n",
        "def Web_dev_handoff(ctx: RunContextWrapper[None]):\n",
        "  print(\"\\n\\n\\nHandsOff to Web Dev Agent\")\n",
        "\n",
        "def Mobile_dev_handoff(ctx: RunContextWrapper[None]):\n",
        "  print(\"\\n\\n\\nHandsOff to Web Dev Agent\")\n",
        "\n",
        "def Agentic_AI_handoff(ctx: RunContextWrapper[None]):\n",
        "  print(\"\\n\\n\\nHandsOff to Web Dev Agent\")\n",
        "PanaCloud = Agent(\n",
        "    name='PanaCloud',\n",
        "    instructions=dynamic_instructions,\n",
        "    model=model,\n",
        "    handoffs=[\n",
        "        handoff(WebDev, on_handoff = Web_dev_handoff,),\n",
        "        handoff(Mobile_Dev, on_handoff = Mobile_dev_handoff,),\n",
        "        handoff(Agentic_AI, on_handoff = Agentic_AI_handoff,),\n",
        "    ],\n",
        "    tools=[tavily_search]\n",
        ")\n",
        "\n",
        "async def main():\n",
        "  msg1 = \"What’s the best way to handle push notifications in a mobile app?\" # → Mobile_Dev\n",
        "  msg2 = \"What are the differences between GPT-3 and GPT-4?\"             # → Agentic_AI → OpenAiAgent\n",
        "  msg3 = \"How do I deploy a containerized app using Kubernetes?\"     # → Agentic_AI → DevOps\n",
        "  msg4 = \"I need help styling a webpage using CSS.\"                 # → WebDev\n",
        "  result =  await Runner.run(PanaCloud, \"What is Open AI Agent SDK\")\n",
        "  last_agent = result.last_agent\n",
        "  print(f\"\\n\\nLast agent called: {last_agent.name}\")\n",
        "\n",
        "  print(f\"\\n\\nFinal response:\\n{result.final_output}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    asyncio.run(main())"
      ],
      "metadata": {
        "id": "30Qczm2XFASA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7573a161-6cf2-4886-cc54-4bdd5b80fc0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:openai.agents:OPENAI_API_KEY is not set, skipping trace export\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "HandsOff to Web Dev Agent\n",
            "\n",
            "\n",
            "Last agent called: Agentic_AI\n",
            "\n",
            "\n",
            "Final response:\n",
            "To clarify, are you asking about the OpenAI Agent SDK, or more generally about agent SDKs that can be used with OpenAI models?\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "draw_graph(PanaCloud)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "id": "erxex7Sv4P-V",
        "outputId": "9706e72f-61a9-434e-d94f-50d27c495a70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.43.0 (0)\n -->\n<!-- Title: G Pages: 1 -->\n<svg width=\"520pt\" height=\"229pt\"\n viewBox=\"0.00 0.00 520.18 228.53\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 224.53)\">\n<title>G</title>\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-224.53 516.18,-224.53 516.18,4 -4,4\"/>\n<!-- __start__ -->\n<g id=\"node1\" class=\"node\">\n<title>__start__</title>\n<ellipse fill=\"lightblue\" stroke=\"black\" cx=\"206.18\" cy=\"-204.26\" rx=\"51.74\" ry=\"16.03\"/>\n<text text-anchor=\"middle\" x=\"206.18\" y=\"-200.56\" font-family=\"Arial\" font-size=\"14.00\">__start__</text>\n</g>\n<!-- PanaCloud -->\n<g id=\"node3\" class=\"node\">\n<title>PanaCloud</title>\n<polygon fill=\"lightyellow\" stroke=\"black\" points=\"260.18,-152 152.18,-152 152.18,-94 260.18,-94 260.18,-152\"/>\n<text text-anchor=\"middle\" x=\"206.18\" y=\"-119.3\" font-family=\"Arial\" font-size=\"14.00\">PanaCloud</text>\n</g>\n<!-- __start__&#45;&gt;PanaCloud -->\n<g id=\"edge1\" class=\"edge\">\n<title>__start__&#45;&gt;PanaCloud</title>\n<path fill=\"none\" stroke=\"black\" stroke-width=\"1.5\" d=\"M206.18,-187.98C206.18,-180.59 206.18,-171.36 206.18,-162.23\"/>\n<polygon fill=\"black\" stroke=\"black\" stroke-width=\"1.5\" points=\"209.68,-162.07 206.18,-152.07 202.68,-162.07 209.68,-162.07\"/>\n</g>\n<!-- __end__ -->\n<g id=\"node2\" class=\"node\">\n<title>__end__</title>\n<ellipse fill=\"lightblue\" stroke=\"black\" cx=\"324.18\" cy=\"-204.26\" rx=\"48.58\" ry=\"16.03\"/>\n<text text-anchor=\"middle\" x=\"324.18\" y=\"-200.56\" font-family=\"Arial\" font-size=\"14.00\">__end__</text>\n</g>\n<!-- tavily_search -->\n<g id=\"node4\" class=\"node\">\n<title>tavily_search</title>\n<ellipse fill=\"lightgreen\" stroke=\"black\" cx=\"67.18\" cy=\"-29\" rx=\"67.35\" ry=\"16.03\"/>\n<text text-anchor=\"middle\" x=\"67.18\" y=\"-25.3\" font-family=\"Arial\" font-size=\"14.00\">tavily_search</text>\n</g>\n<!-- PanaCloud&#45;&gt;tavily_search -->\n<g id=\"edge2\" class=\"edge\">\n<title>PanaCloud&#45;&gt;tavily_search</title>\n<path fill=\"none\" stroke=\"black\" stroke-width=\"1.5\" stroke-dasharray=\"1,5\" d=\"M157.44,-93.9C135.67,-80 110.95,-63.52 92.82,-50.78\"/>\n<polygon fill=\"black\" stroke=\"black\" stroke-width=\"1.5\" points=\"94.67,-47.8 84.49,-44.85 90.61,-53.51 94.67,-47.8\"/>\n</g>\n<!-- WebDev -->\n<g id=\"node5\" class=\"node\">\n<title>WebDev</title>\n<path fill=\"none\" stroke=\"black\" d=\"M248.18,-58C248.18,-58 164.18,-58 164.18,-58 158.18,-58 152.18,-52 152.18,-46 152.18,-46 152.18,-12 152.18,-12 152.18,-6 158.18,0 164.18,0 164.18,0 248.18,0 248.18,0 254.18,0 260.18,-6 260.18,-12 260.18,-12 260.18,-46 260.18,-46 260.18,-52 254.18,-58 248.18,-58\"/>\n<text text-anchor=\"middle\" x=\"206.18\" y=\"-25.3\" font-family=\"Arial\" font-size=\"14.00\">WebDev</text>\n</g>\n<!-- PanaCloud&#45;&gt;WebDev -->\n<g id=\"edge4\" class=\"edge\">\n<title>PanaCloud&#45;&gt;WebDev</title>\n<path fill=\"none\" stroke=\"black\" stroke-width=\"1.5\" d=\"M206.18,-93.9C206.18,-85.86 206.18,-76.95 206.18,-68.41\"/>\n<polygon fill=\"black\" stroke=\"black\" stroke-width=\"1.5\" points=\"209.68,-68.25 206.18,-58.25 202.68,-68.25 209.68,-68.25\"/>\n</g>\n<!-- Mobile_Dev -->\n<g id=\"node6\" class=\"node\">\n<title>Mobile_Dev</title>\n<path fill=\"none\" stroke=\"black\" d=\"M374.18,-58C374.18,-58 290.18,-58 290.18,-58 284.18,-58 278.18,-52 278.18,-46 278.18,-46 278.18,-12 278.18,-12 278.18,-6 284.18,0 290.18,0 290.18,0 374.18,0 374.18,0 380.18,0 386.18,-6 386.18,-12 386.18,-12 386.18,-46 386.18,-46 386.18,-52 380.18,-58 374.18,-58\"/>\n<text text-anchor=\"middle\" x=\"332.18\" y=\"-25.3\" font-family=\"Arial\" font-size=\"14.00\">Mobile_Dev</text>\n</g>\n<!-- PanaCloud&#45;&gt;Mobile_Dev -->\n<g id=\"edge5\" class=\"edge\">\n<title>PanaCloud&#45;&gt;Mobile_Dev</title>\n<path fill=\"none\" stroke=\"black\" stroke-width=\"1.5\" d=\"M244.66,-93.9C257.49,-84.53 271.92,-74 285.31,-64.22\"/>\n<polygon fill=\"black\" stroke=\"black\" stroke-width=\"1.5\" points=\"287.48,-66.97 293.49,-58.25 283.35,-61.32 287.48,-66.97\"/>\n</g>\n<!-- Agentic_AI -->\n<g id=\"node7\" class=\"node\">\n<title>Agentic_AI</title>\n<path fill=\"none\" stroke=\"black\" d=\"M500.18,-58C500.18,-58 416.18,-58 416.18,-58 410.18,-58 404.18,-52 404.18,-46 404.18,-46 404.18,-12 404.18,-12 404.18,-6 410.18,0 416.18,0 416.18,0 500.18,0 500.18,0 506.18,0 512.18,-6 512.18,-12 512.18,-12 512.18,-46 512.18,-46 512.18,-52 506.18,-58 500.18,-58\"/>\n<text text-anchor=\"middle\" x=\"458.18\" y=\"-25.3\" font-family=\"Arial\" font-size=\"14.00\">Agentic_AI</text>\n</g>\n<!-- PanaCloud&#45;&gt;Agentic_AI -->\n<g id=\"edge6\" class=\"edge\">\n<title>PanaCloud&#45;&gt;Agentic_AI</title>\n<path fill=\"none\" stroke=\"black\" stroke-width=\"1.5\" d=\"M260.42,-105.09C296.23,-93.6 344.29,-77.54 394.6,-58.12\"/>\n<polygon fill=\"black\" stroke=\"black\" stroke-width=\"1.5\" points=\"395.96,-61.34 404.01,-54.45 393.42,-54.82 395.96,-61.34\"/>\n</g>\n<!-- tavily_search&#45;&gt;PanaCloud -->\n<g id=\"edge3\" class=\"edge\">\n<title>tavily_search&#45;&gt;PanaCloud</title>\n<path fill=\"none\" stroke=\"black\" stroke-width=\"1.5\" stroke-dasharray=\"1,5\" d=\"M93.48,-44.09C112.73,-55.79 139.14,-72.94 161.6,-88.17\"/>\n<polygon fill=\"black\" stroke=\"black\" stroke-width=\"1.5\" points=\"159.76,-91.15 169.99,-93.9 163.7,-85.37 159.76,-91.15\"/>\n</g>\n</g>\n</svg>\n",
            "text/plain": [
              "<graphviz.sources.Source at 0x79f54ec40990>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UDgp-HIF4fla"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}